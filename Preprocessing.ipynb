{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b01e1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: underthesea in /Users/trkien/.local/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: unidecode in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from underthesea) (1.2.0)\n",
      "Requirement already satisfied: underthesea-core==0.0.4_alpha.10 in /Users/trkien/.local/lib/python3.9/site-packages (from underthesea) (0.0.4a10)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in /Users/trkien/.local/lib/python3.9/site-packages (from underthesea) (0.9.8)\n",
      "Requirement already satisfied: PyYAML in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from underthesea) (6.0)\n",
      "Requirement already satisfied: joblib in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from underthesea) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from underthesea) (1.0.2)\n",
      "Requirement already satisfied: Click>=6.0 in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from underthesea) (8.0.4)\n",
      "Requirement already satisfied: nltk in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from underthesea) (3.7)\n",
      "Requirement already satisfied: requests in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from underthesea) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from underthesea) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from nltk->underthesea) (2022.3.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from requests->underthesea) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from requests->underthesea) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from requests->underthesea) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from requests->underthesea) (3.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->underthesea) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->underthesea) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/trkien/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->underthesea) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt một số hàm tiền xử lý văn bản cần thiết\n",
    "!pip3 install --user underthesea\n",
    "import regex as re\n",
    "from underthesea import word_tokenize\n",
    " \n",
    "uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
    "unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
    " \n",
    "def loaddicchar():\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "        '|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    "dicchar = loaddicchar()\n",
    "\n",
    "# Hàm chuyển Unicode dựng sẵn về Unicde tổ hợp (phổ biến hơn)\n",
    "def convert_unicode(txt):\n",
    "    return re.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar[x.group()], txt)\n",
    "\n",
    "bang_nguyen_am = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
    "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
    "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
    "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
    "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
    "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
    "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
    "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
    "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
    "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
    "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
    "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
    "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
    "\n",
    "nguyen_am_to_ids = {}\n",
    "\n",
    "for i in range(len(bang_nguyen_am)):\n",
    "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
    "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
    "\n",
    "def chuan_hoa_dau_tu_tieng_viet(word):\n",
    "    if not is_valid_vietnam_word(word):\n",
    "        return word\n",
    "\n",
    "    chars = list(word)\n",
    "    dau_cau = 0\n",
    "    nguyen_am_index = []\n",
    "    qu_or_gi = False\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x == -1:\n",
    "            continue\n",
    "        elif x == 9:  # check qu\n",
    "            if index != 0 and chars[index - 1] == 'q':\n",
    "                chars[index] = 'u'\n",
    "                qu_or_gi = True\n",
    "        elif x == 5:  # check gi\n",
    "            if index != 0 and chars[index - 1] == 'g':\n",
    "                chars[index] = 'i'\n",
    "                qu_or_gi = True\n",
    "        if y != 0:\n",
    "            dau_cau = y\n",
    "            chars[index] = bang_nguyen_am[x][0]\n",
    "        if not qu_or_gi or index != 1:\n",
    "            nguyen_am_index.append(index)\n",
    "    if len(nguyen_am_index) < 2:\n",
    "        if qu_or_gi:\n",
    "            if len(chars) == 2:\n",
    "                x, y = nguyen_am_to_ids.get(chars[1])\n",
    "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
    "            else:\n",
    "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
    "                if x != -1:\n",
    "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
    "                else:\n",
    "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
    "            return ''.join(chars)\n",
    "        return word\n",
    "\n",
    "    for index in nguyen_am_index:\n",
    "        x, y = nguyen_am_to_ids[chars[index]]\n",
    "        if x == 4 or x == 8:  # ê, ơ\n",
    "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
    "            # for index2 in nguyen_am_index:\n",
    "            #     if index2 != index:\n",
    "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
    "            #         chars[index2] = bang_nguyen_am[x][0]\n",
    "            return ''.join(chars)\n",
    "\n",
    "    if len(nguyen_am_index) == 2:\n",
    "        if nguyen_am_index[-1] == len(chars) - 1:\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
    "        else:\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "    else:\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
    "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
    "    return ''.join(chars)\n",
    "\n",
    "\n",
    "def is_valid_vietnam_word(word):\n",
    "    chars = list(word)\n",
    "    nguyen_am_index = -1\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x != -1:\n",
    "            if nguyen_am_index == -1:\n",
    "                nguyen_am_index = index\n",
    "            else:\n",
    "                if index - nguyen_am_index != 1:\n",
    "                    return False\n",
    "                nguyen_am_index = index\n",
    "    return True\n",
    "\n",
    "\n",
    "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
    "    \"\"\"\n",
    "        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n",
    "        :param sentence:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    for index, word in enumerate(words):\n",
    "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
    "        # print(cw)\n",
    "        if len(cw) == 3:\n",
    "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
    "        words[index] = ''.join(cw)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_html(txt):\n",
    "    return re.sub(r'<[^>]*>', '', txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9038aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anh phạm anh quý đăng_ký 3 bib cho mình và 2 con_trai tham_gia aquaman vietnam 210 nhằm tìm thử_thách mới trên chặng đường luyện_tập thể_thao ba ngày sau khi mở cổng đăng_ký giải aquathlon bơi chạy aquaman vietnam hàng trăm vận_động_viên vận_động_viên đã mua bib thành_công họ xem giải là cơ_hội để tìm_kiếm cảm_giác thi_đấu mới_mẻ trải_nghiệm các dạng địa_hình thi_đấu khác nhau anh phạm anh quý chân_chạy quen_mặt tại vnexpress marathon là một trong những người đầu_tiên mua bib aquaman vietnam vốn là người yêu thích các môn thể_thao phối_hợp nhưng do số_lượng giải_hạn_chế anh lúc_nào cũng trong tình_trạng khát vận_động anh quý sẽ bơi 2 km và chạy 21 km trong khi hai bé sẽ chinh_phục cự_ly trẻ_em là bơi 200 m và chạy 1 km hai con đã biết bơi từ 5 tuổi và giờ có_thể bơi được khoảng 2 km nên tôi không quá lo_lắng anh nói\n"
     ]
    }
   ],
   "source": [
    "def text_preprocess(document):\n",
    "    # xóa html code\n",
    "    document = remove_html(document)\n",
    "    # chuẩn hóa unicode\n",
    "    document = convert_unicode(document)\n",
    "    # chuẩn hóa cách gõ dấu tiếng Việt\n",
    "    document = chuan_hoa_dau_cau_tieng_viet(document)\n",
    "    # tách từ\n",
    "    document = word_tokenize(document, format=\"text\")\n",
    "    # đưa về lower\n",
    "    document = document.lower()\n",
    "    # xóa các ký tự không cần thiết\n",
    "    document = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',document)\n",
    "    # xóa khoảng trắng thừa\n",
    "    document = re.sub(r'\\s+', ' ', document).strip()\n",
    "    return document\n",
    "\n",
    "document = \"\"\"\n",
    "Anh Phạm Anh Quý đăng ký 3 Bib cho mình và 2 con trai tham gia Aquaman Vietnam (2/10) nhằm tìm thử thách mới trên chặng đường luyện tập thể thao.\n",
    "Ba ngày sau khi mở cổng đăng ký giải aquathlon (bơi - chạy) Aquaman Vietnam, hàng trăm vận động viên vận động viên đã mua Bib thành công. Họ xem giải là cơ hội để tìm kiếm cảm giác thi đấu mới mẻ, trải nghiệm các dạng địa hình thi đấu khác nhau.\n",
    "Anh Phạm Anh Quý - chân chạy quen mặt tại VnExpress Marathon là một trong những người đầu tiên mua Bib Aquaman Vietnam. Vốn là người yêu thích các môn thể thao phối hợp nhưng do số lượng giải hạn chế, anh lúc nào cũng trong tình trạng \"khát vận động\". \n",
    "Anh Quý sẽ bơi 2 km và chạy 21 km trong khi hai bé sẽ chinh phục cự ly trẻ em là bơi 200 m và chạy 1 km. \"Hai con đã biết bơi từ 5 tuổi và giờ có thể bơi được khoảng 2 km nên tôi không quá lo lắng\" anh nói.\n",
    "\"\"\"\n",
    "document = text_preprocess(document)\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0eacc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
